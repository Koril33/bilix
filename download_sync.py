import math
import time
from collections import OrderedDict, defaultdict
from concurrent.futures.thread import ThreadPoolExecutor
from pathlib import Path
from typing import Optional

import httpx
from curl_cffi import requests
import typer
from curl_cffi.requests.exceptions import HTTPError, RequestException
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, TextColumn, BarColumn, TaskProgressColumn, TimeRemainingColumn, TimeElapsedColumn, \
    MofNCompleteColumn, FileSizeColumn, TotalFileSizeColumn, SpinnerColumn
from rich.text import Text

from log_config import app_logger
from tool import extract_title, extract_playinfo_json, merge_m4s_ffmpeg, extract_initial_state_json, \
    extract_playurl_ssr_data

# B ç«™è§†é¢‘ç¼–ç 
codec_dict = {
    7: 'AVC(H.264)',
    12: 'HEVC(H.265)',
    13: 'AV1',
}

def get_video_info(url: str, header: dict):
    parse_res = parse(url, header)
    console = Console()

    video_url = url
    video_title = parse_res['title']
    if parse_res.get('playurl_ssr_data'):
        result = parse_res.get('playurl_ssr_data').get('result')
        raw = parse_res.get('playurl_ssr_data').get('raw')

        if result:
            video_info = result.get('video_info')
        elif raw:
            video_info = raw.get('data').get('video_info')
        else:
            app_logger.error(f"æ— æ³•è·å–è¯¥ URL : {url} çš„ video_info")
            raise typer.Exit(code=1)

        dash_video = video_info['dash']['video']
        codecid_dict = defaultdict(list)
        for v in dash_video:
            codecid_dict[v['id']].append(codec_dict.get(v['codecid']))

        accept_quality = video_info['accept_quality']
        accept_description = video_info['accept_description']

        timelength = video_info['timelength']
        video_format = video_info['format']

    elif parse_res.get('playinfo'):
        data = parse_res.get('playinfo').get('data')
        accept_quality = data['accept_quality']
        accept_description = data['accept_description']
        timelength = data['timelength']
        video_format = data['format']

        dash_video = data['dash']['video']
        codecid_dict = defaultdict(list)
        for v in dash_video:
            codecid_dict[v['id']].append(codec_dict.get(v['codecid']))
    else:
        app_logger.error("æ— æ³•æ‰¾åˆ°è§†é¢‘ä¿¡æ¯")
        return

    qualities = OrderedDict(zip(accept_quality, accept_description))

    # è§†é¢‘æ—¶é•¿æ¯«ç§’è½¬åˆ†é’Ÿç§’çš„å­—ç¬¦ä¸²æ ¼å¼
    total_seconds = math.ceil(timelength / 1000)
    minutes, seconds = divmod(total_seconds, 60)

    # æ„é€ å†…å®¹
    text = Text()
    text.append("è§†é¢‘ URLï¼š", style="bold cyan")
    text.append(video_url + "\n", style="bold green")
    text.append("è§†é¢‘æ ‡é¢˜ï¼š", style="bold cyan")
    text.append(video_title + "\n", style="bold magenta")
    text.append("è§†é¢‘æ ¼å¼ï¼š", style="bold cyan")
    text.append(str(video_format) + "\n", style="bold magenta")
    text.append("è§†é¢‘æ—¶é•¿ï¼š", style="bold cyan")
    text.append(f'{minutes} åˆ† {seconds} ç§’' + "\n\n", style="bold magenta")

    text.append("å¯é€‰æ‹©æ¸…æ™°åº¦ï¼š\n", style="bold yellow")

    for key, value in qualities.items():
        text.append(f"{key} - {value} - æ”¯æŒç¼–ç : {codecid_dict.get(key)}\n", style="bold white")

    if parse_res.get('initial_state'):
        pages_info = parse_res.get('initial_state').get('videoData').get('pages')
        text.append("\né€‰é›†ä¿¡æ¯ï¼š\n", style="bold yellow")
        for page in pages_info:
            # è½¬æ¢æ—¶é•¿æ ¼å¼ï¼ˆç§’ -> åˆ†:ç§’ï¼‰
            minutes, seconds = divmod(page['duration'], 60)
            duration_str = f"{minutes:02d}:{seconds:02d}"
            text.append(
                f"ç¬¬{page['page']}é›† - æ—¶é•¿: {duration_str} - <{page['part']}>\n",
                style="bold white"
            )

    # ä½¿ç”¨ Panel åŒ…è£¹å†…å®¹
    panel = Panel(
        text,
        title="ğŸ¬ è§†é¢‘ä¿¡æ¯",
        title_align="left",
        border_style="bright_blue",
        padding=(1, 2),
    )

    console.print(panel)



def parse(url: str, headers: dict):
    with requests.Session() as session:
        try:
            response = session.get(url=url, headers=headers, timeout=5)
            response.raise_for_status()

            html = response.text
            title = extract_title(html)
            playinfo = extract_playinfo_json(html)
            initial_state = extract_initial_state_json(html)
            playurl_ssr_data = extract_playurl_ssr_data(html)

            if playinfo:
                app_logger.info("æˆåŠŸæå–åˆ° playinfo JSON")
            else:
                app_logger.error("æœªèƒ½æå–åˆ° playinfo JSONã€‚")

            if initial_state:
                app_logger.info("æˆåŠŸæå–åˆ° initial state JSON")
            else:
                app_logger.error("æœªèƒ½æå–åˆ° initial state JSONã€‚")

            if playurl_ssr_data:
                app_logger.info("æˆåŠŸæå–åˆ° playurl_ssr_data JSON")
            else:
                app_logger.error("æœªèƒ½æå–åˆ° playurl_ssr_data JSONã€‚")
            return {
                'title': title,
                'playinfo': playinfo,
                'initial_state': initial_state,
                'playurl_ssr_data': playurl_ssr_data,
            }
        except HTTPError:
            app_logger.exception(f'HTTP é”™è¯¯')
        except RequestException:
            app_logger.exception(f'ä¸‹è½½å¤±è´¥ï¼Œç½‘ç»œè¯·æ±‚é”™è¯¯')
        except Exception:
            app_logger.exception(f'æœªçŸ¥é”™è¯¯')
    return None


def download_stream(url: str, headers, filename: str, progress):
    task = progress.add_task(f'{filename}', start=False)
    with httpx.Client(proxy=None, trust_env=False).stream("GET", url=url, headers=headers) as resp:
        resp.raise_for_status()
        total = int(resp.headers.get('Content-Length', 0))
        progress.update(task, total=total)
        progress.start_task(task)
        with open(filename, 'wb') as f:
            for chunk in resp.iter_bytes(chunk_size=1024 * 1024):
                f.write(chunk)
                progress.update(task, advance=len(chunk))


def download_sync(
        url: str,
        headers: dict,
        quality: Optional[int] = None,
        save: str = None,
):
    parse_res = parse(url, headers)
    title = parse_res.get('title')
    playinfo = parse_res.get('playinfo')
    playurl_info = parse_res.get('playurl_ssr_data')

    if playurl_info:
        dash = playurl_info['result'].get('video_info').get('dash')
        videos = dash.get('video', [])
        audios = dash.get('audio', [])
    else:
        if not playinfo or 'data' not in playinfo:
            app_logger.error(f"æ— æ³•è·å–è¯¥ URL : {url} çš„æ’­æ”¾ä¿¡æ¯, è¯·æ£€æŸ¥è¯¥è§†é¢‘åœ°å€çš„æ­£ç¡®æ€§æˆ–è€…è¯¥è§†é¢‘çš„ä¸‹è½½éœ€è¦å¤§ä¼šå‘˜è´¦å·æƒé™")
            raise typer.Exit(code=1)

        dash = playinfo['data'].get('dash', {})
        videos = dash.get('video', [])
        audios = dash.get('audio', [])
        if not videos or not audios:
            app_logger.error("æœªæ£€æµ‹åˆ°è§†é¢‘æˆ–éŸ³é¢‘æµï¼Œé€€å‡ºã€‚")
            raise typer.Exit(code=1)

    # é€‰æ‹©è§†é¢‘æµ
    if quality:
        selected = next((v for v in videos if v['id'] == quality), None)
        if not selected:
            app_logger.info(f"æœªæ‰¾åˆ°æ¸…æ™°åº¦ {quality}ï¼Œä½¿ç”¨æœ€é«˜è´¨é‡ã€‚")
            selected = videos[0]
    else:
        selected = videos[0]

    video_url = selected.get('baseUrl') or selected.get('base_url')
    # é€‰æ‹©éŸ³é¢‘æµï¼ˆé»˜è®¤æœ€é«˜ï¼‰
    audio = audios[0]
    audio_url = audio.get('baseUrl') or audio.get('base_url')

    video_file = f'{title}_v_{selected["id"]}.m4s'
    audio_file = f'{title}_a_{selected["id"]}.m4s'
    start = int(time.time() * 1000)

    with Progress(
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TaskProgressColumn(),
        TimeRemainingColumn(),
        TimeElapsedColumn(),
        MofNCompleteColumn(),
        FileSizeColumn(),
        TotalFileSizeColumn(),
        SpinnerColumn(),
    ) as progress:
        with ThreadPoolExecutor(max_workers=2) as executor:
            executor.submit(download_stream, video_url, headers, video_file, progress)
            executor.submit(download_stream, audio_url, headers, audio_file, progress)


    end = int(time.time() * 1000)
    app_logger.info(f'ä¸‹è½½éŸ³è§†é¢‘å…±è€—æ—¶: {end - start} ms')

    if save:
        save_path = Path(save)
        save_path.mkdir(parents=True, exist_ok=True)
    else:
        save_path = Path('.')  # å½“å‰ç›®å½•
    output_path = save_path / f'{title}_{selected["id"]}.mp4'
    if output_path.exists():
        app_logger.warning('ç›®æ ‡MP4å­˜åœ¨ï¼Œè¿›è¡Œåˆ é™¤')
        output_path.unlink()

    app_logger.info("æ‰€æœ‰æµä¸‹è½½å®Œæˆï¼Œä½¿ç”¨ ffmpeg åˆå¹¶éŸ³è§†é¢‘")
    merge_m4s_ffmpeg(video_file, audio_file, str(output_path))
    Path.unlink(Path(video_file), missing_ok=True)
    Path.unlink(Path(audio_file), missing_ok=True)